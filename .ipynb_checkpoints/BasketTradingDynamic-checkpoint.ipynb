{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functions as fn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy: Dynamic Entries and Exits\n",
    "The dynamic strategy considers volatility (standard deviation) of the spread when constructing entries and exits.  A lookback period is chosen and an exponential moving average is computed for that lookback period.  A constant is also chosen that represents how many standard deviations the bands should encompass.  When the spread exceeds the upper band, a short signal is generated.  When the spread is below the lower band, a long signal is generated.  The signal ends when the spread crosses the exponential moving average again.  Positions are taken in the minute immediately after the signal is generated.  Positions are also closed by the end of the day and no overnight positions are ever taken.\n",
    "\n",
    "Minute level data from 2018 is used to tune the parameters of the dynamic entries and exits.  These parameters include a lookback period and how wide the bands should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from 01-01-2018 and end at 12-31-2018\n",
    "qqq2018 = pd.read_csv(\"../data/qqqMinute2018.csv\")\n",
    "has2018 = pd.read_csv(\"../data/hasMinute2018.csv\")\n",
    "aapl2018 = pd.read_csv(\"../data/aaplMinute2018.csv\")\n",
    "ttwo2018 = pd.read_csv(\"../data/ttwoMinute2018.csv\")\n",
    "idxx2018 = pd.read_csv(\"../data/idxxMinute2018.csv\")\n",
    "sbux2018 = pd.read_csv(\"../data/sbuxMinute2018.csv\")\n",
    "ctas2018 = pd.read_csv(\"../data/ctasMinute2018.csv\")\n",
    "alxn2018 = pd.read_csv(\"../data/alxnMinute2018.csv\")\n",
    "algn2018 = pd.read_csv(\"../data/algnMinute2018.csv\")\n",
    "payx2018 = pd.read_csv(\"../data/payxMinute2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqq2018 = qqq2018.set_index('date_time')\n",
    "qqq2018 = qqq2018.rename(columns={'close': 'qqqclose'})\n",
    "\n",
    "has2018 = has2018.set_index('date_time')\n",
    "has2018 = has2018.rename(columns={'close': 'hasclose'})\n",
    "\n",
    "aapl2018 = aapl2018.set_index('date_time')\n",
    "aapl2018 = aapl2018.rename(columns={'close': 'aaplclose'})\n",
    "\n",
    "ttwo2018 = ttwo2018.set_index('date_time')\n",
    "ttwo2018 = ttwo2018.rename(columns={'close': 'ttwoclose'})\n",
    "\n",
    "idxx2018 = idxx2018.set_index('date_time')\n",
    "idxx2018 = idxx2018.rename(columns={'close': 'idxxclose'})\n",
    "\n",
    "sbux2018 = sbux2018.set_index('date_time')\n",
    "sbux2018 = sbux2018.rename(columns={'close': 'sbuxclose'})\n",
    "\n",
    "ctas2018 = ctas2018.set_index('date_time')\n",
    "ctas2018 = ctas2018.rename(columns={'close': 'ctasclose'})\n",
    "\n",
    "alxn2018 = alxn2018.set_index('date_time')\n",
    "alxn2018 = alxn2018.rename(columns={'close': 'alxnclose'})\n",
    "\n",
    "algn2018 = algn2018.set_index('date_time')\n",
    "algn2018 = algn2018.rename(columns={'close': 'algnclose'})\n",
    "\n",
    "payx2018 = payx2018.set_index('date_time')\n",
    "payx2018 = payx2018.rename(columns={'close': 'payxclose'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for Engle-Granger Basket in 2018 (In-Sample Period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qqqclose</th>\n",
       "      <th>hasclose</th>\n",
       "      <th>aaplclose</th>\n",
       "      <th>ttwoclose</th>\n",
       "      <th>sbuxclose</th>\n",
       "      <th>ctasclose</th>\n",
       "      <th>alxnclose</th>\n",
       "      <th>algnclose</th>\n",
       "      <th>payxclose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:40:00</th>\n",
       "      <td>153.7400</td>\n",
       "      <td>81.2300</td>\n",
       "      <td>157.2500</td>\n",
       "      <td>103.1094</td>\n",
       "      <td>64.2900</td>\n",
       "      <td>167.4819</td>\n",
       "      <td>97.3400</td>\n",
       "      <td>209.6600</td>\n",
       "      <td>64.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:41:00</th>\n",
       "      <td>153.8144</td>\n",
       "      <td>81.2800</td>\n",
       "      <td>157.3299</td>\n",
       "      <td>103.1242</td>\n",
       "      <td>64.3000</td>\n",
       "      <td>167.4850</td>\n",
       "      <td>97.2400</td>\n",
       "      <td>209.6400</td>\n",
       "      <td>64.9962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:42:00</th>\n",
       "      <td>153.8100</td>\n",
       "      <td>81.3309</td>\n",
       "      <td>157.3600</td>\n",
       "      <td>103.1000</td>\n",
       "      <td>64.3650</td>\n",
       "      <td>167.5400</td>\n",
       "      <td>97.1800</td>\n",
       "      <td>209.6369</td>\n",
       "      <td>65.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:43:00</th>\n",
       "      <td>153.8500</td>\n",
       "      <td>81.2500</td>\n",
       "      <td>157.4300</td>\n",
       "      <td>103.1250</td>\n",
       "      <td>64.3650</td>\n",
       "      <td>167.6300</td>\n",
       "      <td>97.2800</td>\n",
       "      <td>209.7700</td>\n",
       "      <td>65.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:44:00</th>\n",
       "      <td>153.7760</td>\n",
       "      <td>81.2350</td>\n",
       "      <td>157.3800</td>\n",
       "      <td>103.0750</td>\n",
       "      <td>64.3679</td>\n",
       "      <td>167.5700</td>\n",
       "      <td>97.1400</td>\n",
       "      <td>209.4100</td>\n",
       "      <td>65.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:45:00</th>\n",
       "      <td>153.7900</td>\n",
       "      <td>81.2500</td>\n",
       "      <td>157.3400</td>\n",
       "      <td>103.0300</td>\n",
       "      <td>64.3700</td>\n",
       "      <td>167.5600</td>\n",
       "      <td>97.1317</td>\n",
       "      <td>209.5250</td>\n",
       "      <td>65.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:46:00</th>\n",
       "      <td>153.7700</td>\n",
       "      <td>81.2100</td>\n",
       "      <td>157.3484</td>\n",
       "      <td>102.9700</td>\n",
       "      <td>64.3850</td>\n",
       "      <td>167.4601</td>\n",
       "      <td>97.0600</td>\n",
       "      <td>209.4700</td>\n",
       "      <td>65.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:47:00</th>\n",
       "      <td>153.6800</td>\n",
       "      <td>81.1400</td>\n",
       "      <td>157.2915</td>\n",
       "      <td>102.9300</td>\n",
       "      <td>64.3500</td>\n",
       "      <td>167.3100</td>\n",
       "      <td>96.9800</td>\n",
       "      <td>209.3500</td>\n",
       "      <td>65.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:48:00</th>\n",
       "      <td>153.5750</td>\n",
       "      <td>81.0300</td>\n",
       "      <td>157.2400</td>\n",
       "      <td>102.8200</td>\n",
       "      <td>64.3200</td>\n",
       "      <td>167.2500</td>\n",
       "      <td>96.8900</td>\n",
       "      <td>209.1300</td>\n",
       "      <td>65.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:49:00</th>\n",
       "      <td>153.4300</td>\n",
       "      <td>80.9600</td>\n",
       "      <td>157.1500</td>\n",
       "      <td>102.6050</td>\n",
       "      <td>64.2500</td>\n",
       "      <td>167.1700</td>\n",
       "      <td>96.8000</td>\n",
       "      <td>208.7400</td>\n",
       "      <td>64.9500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     qqqclose  hasclose  aaplclose  ttwoclose  sbuxclose  \\\n",
       "2018-12-31 15:40:00  153.7400   81.2300   157.2500   103.1094    64.2900   \n",
       "2018-12-31 15:41:00  153.8144   81.2800   157.3299   103.1242    64.3000   \n",
       "2018-12-31 15:42:00  153.8100   81.3309   157.3600   103.1000    64.3650   \n",
       "2018-12-31 15:43:00  153.8500   81.2500   157.4300   103.1250    64.3650   \n",
       "2018-12-31 15:44:00  153.7760   81.2350   157.3800   103.0750    64.3679   \n",
       "2018-12-31 15:45:00  153.7900   81.2500   157.3400   103.0300    64.3700   \n",
       "2018-12-31 15:46:00  153.7700   81.2100   157.3484   102.9700    64.3850   \n",
       "2018-12-31 15:47:00  153.6800   81.1400   157.2915   102.9300    64.3500   \n",
       "2018-12-31 15:48:00  153.5750   81.0300   157.2400   102.8200    64.3200   \n",
       "2018-12-31 15:49:00  153.4300   80.9600   157.1500   102.6050    64.2500   \n",
       "\n",
       "                     ctasclose  alxnclose  algnclose  payxclose  \n",
       "2018-12-31 15:40:00   167.4819    97.3400   209.6600    64.9600  \n",
       "2018-12-31 15:41:00   167.4850    97.2400   209.6400    64.9962  \n",
       "2018-12-31 15:42:00   167.5400    97.1800   209.6369    65.0200  \n",
       "2018-12-31 15:43:00   167.6300    97.2800   209.7700    65.0200  \n",
       "2018-12-31 15:44:00   167.5700    97.1400   209.4100    65.0250  \n",
       "2018-12-31 15:45:00   167.5600    97.1317   209.5250    65.0550  \n",
       "2018-12-31 15:46:00   167.4601    97.0600   209.4700    65.0500  \n",
       "2018-12-31 15:47:00   167.3100    96.9800   209.3500    65.0150  \n",
       "2018-12-31 15:48:00   167.2500    96.8900   209.1300    65.0000  \n",
       "2018-12-31 15:49:00   167.1700    96.8000   208.7400    64.9500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg_basket_data2018 = qqq2018[['qqqclose']].join([has2018[['hasclose']], aapl2018[['aaplclose']], ttwo2018[['ttwoclose']], \n",
    "                                                 sbux2018[['sbuxclose']], ctas2018[['ctasclose']], alxn2018[['alxnclose']], \n",
    "                                                 algn2018[['algnclose']], payx2018[['payxclose']]], how='outer')\n",
    "eg_basket_data2018 = eg_basket_data2018.dropna()\n",
    "eg_basket_data2018.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for Johansen Basket in 2018 (In-Sample Period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qqqclose</th>\n",
       "      <th>hasclose</th>\n",
       "      <th>ttwoclose</th>\n",
       "      <th>idxxclose</th>\n",
       "      <th>sbuxclose</th>\n",
       "      <th>ctasclose</th>\n",
       "      <th>alxnclose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:40:00</th>\n",
       "      <td>153.7400</td>\n",
       "      <td>81.2300</td>\n",
       "      <td>103.1094</td>\n",
       "      <td>185.5024</td>\n",
       "      <td>64.2900</td>\n",
       "      <td>167.4819</td>\n",
       "      <td>97.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:41:00</th>\n",
       "      <td>153.8144</td>\n",
       "      <td>81.2800</td>\n",
       "      <td>103.1242</td>\n",
       "      <td>185.7300</td>\n",
       "      <td>64.3000</td>\n",
       "      <td>167.4850</td>\n",
       "      <td>97.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:42:00</th>\n",
       "      <td>153.8100</td>\n",
       "      <td>81.3309</td>\n",
       "      <td>103.1000</td>\n",
       "      <td>185.6360</td>\n",
       "      <td>64.3650</td>\n",
       "      <td>167.5400</td>\n",
       "      <td>97.1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:43:00</th>\n",
       "      <td>153.8500</td>\n",
       "      <td>81.2500</td>\n",
       "      <td>103.1250</td>\n",
       "      <td>185.9200</td>\n",
       "      <td>64.3650</td>\n",
       "      <td>167.6300</td>\n",
       "      <td>97.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:44:00</th>\n",
       "      <td>153.7760</td>\n",
       "      <td>81.2350</td>\n",
       "      <td>103.0750</td>\n",
       "      <td>185.6000</td>\n",
       "      <td>64.3679</td>\n",
       "      <td>167.5700</td>\n",
       "      <td>97.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:45:00</th>\n",
       "      <td>153.7900</td>\n",
       "      <td>81.2500</td>\n",
       "      <td>103.0300</td>\n",
       "      <td>185.6000</td>\n",
       "      <td>64.3700</td>\n",
       "      <td>167.5600</td>\n",
       "      <td>97.1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:46:00</th>\n",
       "      <td>153.7700</td>\n",
       "      <td>81.2100</td>\n",
       "      <td>102.9700</td>\n",
       "      <td>185.6500</td>\n",
       "      <td>64.3850</td>\n",
       "      <td>167.4601</td>\n",
       "      <td>97.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:47:00</th>\n",
       "      <td>153.6800</td>\n",
       "      <td>81.1400</td>\n",
       "      <td>102.9300</td>\n",
       "      <td>185.4200</td>\n",
       "      <td>64.3500</td>\n",
       "      <td>167.3100</td>\n",
       "      <td>96.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:48:00</th>\n",
       "      <td>153.5750</td>\n",
       "      <td>81.0300</td>\n",
       "      <td>102.8200</td>\n",
       "      <td>185.1750</td>\n",
       "      <td>64.3200</td>\n",
       "      <td>167.2500</td>\n",
       "      <td>96.8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 15:49:00</th>\n",
       "      <td>153.4300</td>\n",
       "      <td>80.9600</td>\n",
       "      <td>102.6050</td>\n",
       "      <td>185.0600</td>\n",
       "      <td>64.2500</td>\n",
       "      <td>167.1700</td>\n",
       "      <td>96.8000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     qqqclose  hasclose  ttwoclose  idxxclose  sbuxclose  \\\n",
       "2018-12-31 15:40:00  153.7400   81.2300   103.1094   185.5024    64.2900   \n",
       "2018-12-31 15:41:00  153.8144   81.2800   103.1242   185.7300    64.3000   \n",
       "2018-12-31 15:42:00  153.8100   81.3309   103.1000   185.6360    64.3650   \n",
       "2018-12-31 15:43:00  153.8500   81.2500   103.1250   185.9200    64.3650   \n",
       "2018-12-31 15:44:00  153.7760   81.2350   103.0750   185.6000    64.3679   \n",
       "2018-12-31 15:45:00  153.7900   81.2500   103.0300   185.6000    64.3700   \n",
       "2018-12-31 15:46:00  153.7700   81.2100   102.9700   185.6500    64.3850   \n",
       "2018-12-31 15:47:00  153.6800   81.1400   102.9300   185.4200    64.3500   \n",
       "2018-12-31 15:48:00  153.5750   81.0300   102.8200   185.1750    64.3200   \n",
       "2018-12-31 15:49:00  153.4300   80.9600   102.6050   185.0600    64.2500   \n",
       "\n",
       "                     ctasclose  alxnclose  \n",
       "2018-12-31 15:40:00   167.4819    97.3400  \n",
       "2018-12-31 15:41:00   167.4850    97.2400  \n",
       "2018-12-31 15:42:00   167.5400    97.1800  \n",
       "2018-12-31 15:43:00   167.6300    97.2800  \n",
       "2018-12-31 15:44:00   167.5700    97.1400  \n",
       "2018-12-31 15:45:00   167.5600    97.1317  \n",
       "2018-12-31 15:46:00   167.4601    97.0600  \n",
       "2018-12-31 15:47:00   167.3100    96.9800  \n",
       "2018-12-31 15:48:00   167.2500    96.8900  \n",
       "2018-12-31 15:49:00   167.1700    96.8000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joh_basket_data2018 = qqq2018[['qqqclose']].join([has2018[['hasclose']], ttwo2018[['ttwoclose']], idxx2018[['idxxclose']], \n",
    "                               sbux2018[['sbuxclose']], ctas2018[['ctasclose']], alxn2018[['alxnclose']]], how='outer')\n",
    "joh_basket_data2018 = joh_basket_data2018.dropna()\n",
    "joh_basket_data2018.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuvi\\Documents\\fall2020\\f20_stat_arb\\functions.py:348: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_data['logspread'] = spread_ts\n",
      "C:\\Users\\liuvi\\Documents\\fall2020\\f20_stat_arb\\functions.py:349: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_data['spread'] = np.exp(spread_ts)\n",
      "C:\\Users\\liuvi\\Documents\\fall2020\\f20_stat_arb\\functions.py:350: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_data['qqqclose'] = dataTemp['qqqclose']\n",
      "C:\\Users\\liuvi\\anaconda3\\envs\\quant\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\liuvi\\anaconda3\\envs\\quant\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3139d4968547>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlookback_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m301\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mz_thresh_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m results_map_eg = fn.tuneBBParameters(eg_basket_data2018, lookback_list, z_thresh_list, \n\u001b[0m\u001b[0;32m      4\u001b[0m                                   ['hasclose', 'aaplclose', 'ttwoclose', 'sbuxclose', \n\u001b[0;32m      5\u001b[0m                                    'ctasclose', 'alxnclose', 'algnclose', 'payxclose'], \n",
      "\u001b[1;32m~\\Documents\\fall2020\\f20_stat_arb\\functions.py\u001b[0m in \u001b[0;36mtuneBBParameters\u001b[1;34m(data, lookbacks, z_threshs, ticker_list, stoploss)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivariateKalmanFilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyntheticAssetLogPrice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqqqLogPrice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mstate_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_covs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqqqLogPrice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m             \u001b[0mslopes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_means\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m#intercept = state_means[:, len(ticker_list)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\quant\\lib\\site-packages\\pykalman\\standard.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1168\u001b[0m         (_, _, _, filtered_state_means,\n\u001b[0;32m   1169\u001b[0m          \u001b[0mfiltered_state_covariances\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m             _filter(\n\u001b[0m\u001b[0;32m   1171\u001b[0m                 \u001b[0mtransition_matrices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation_matrices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m                 \u001b[0mtransition_covariance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation_covariance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\quant\\lib\\site-packages\\pykalman\\standard.py\u001b[0m in \u001b[0;36m_filter\u001b[1;34m(transition_matrices, observation_matrices, transition_covariance, observation_covariance, transition_offsets, observation_offsets, initial_state_mean, initial_state_covariance, observations)\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[0mtransition_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_last_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransition_offsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             predicted_state_means[t], predicted_state_covariances[t] = (\n\u001b[1;32m--> 374\u001b[1;33m                 _filter_predict(\n\u001b[0m\u001b[0;32m    375\u001b[0m                     \u001b[0mtransition_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m                     \u001b[0mtransition_covariance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\quant\\lib\\site-packages\\pykalman\\standard.py\u001b[0m in \u001b[0;36m_filter_predict\u001b[1;34m(transition_matrix, transition_covariance, transition_offset, current_state_mean, current_state_covariance)\u001b[0m\n\u001b[0;32m    210\u001b[0m     predicted_state_covariance = (\n\u001b[0;32m    211\u001b[0m         np.dot(transition_matrix,\n\u001b[1;32m--> 212\u001b[1;33m                np.dot(current_state_covariance,\n\u001b[0m\u001b[0;32m    213\u001b[0m                       transition_matrix.T))\n\u001b[0;32m    214\u001b[0m         \u001b[1;33m+\u001b[0m \u001b[0mtransition_covariance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lookback_list = np.arange(30, 301, 30)\n",
    "z_thresh_list = np.arange(1, 2.6, .25)\n",
    "results_map_eg = fn.tuneBBParameters(eg_basket_data2018, lookback_list, z_thresh_list, \n",
    "                                  ['hasclose', 'aaplclose', 'ttwoclose', 'sbuxclose', \n",
    "                                   'ctasclose', 'alxnclose', 'algnclose', 'payxclose'], \n",
    "                                 stoploss = None)\n",
    "results_map_joh = fn.tuneBBParameters(joh_basket_data2018, lookback_list, z_thresh_list, \n",
    "                                  ['hasclose', 'ttwoclose', 'sbuxclose', \n",
    "                               'idxxclose', 'ctasclose', 'alxnclose'], \n",
    "                                 stoploss = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Engle-Granger Basket Spread Dynamic Strategy Parameters \\n\")\n",
    "params_eg = list(results_map_eg.keys())[0]\n",
    "print(\"Lookback: \", params_eg[0])\n",
    "print(\"Z-Score Threshold: \", params_eg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Johansen Basket Spread Dynamic Strategy Parameters \\n\")\n",
    "params_joh = list(results_map_joh.keys())[0]\n",
    "print(\"Lookback: \", params_joh[0])\n",
    "print(\"Z-Score Threshold: \", params_joh[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Position Threshold\n",
    "To optimize our entries and exits, determine the distribution of spread percentage changes from minute to minute in our in-sample period.  The bottom 20% threshold will be used as a condition for entering positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntheticAssetLogPriceEG2018 = eg_basket_data2018[['hasclose', 'aaplclose', 'ttwoclose', 'sbuxclose', \n",
    "                               'ctasclose', 'alxnclose', 'algnclose', 'payxclose']].apply(np.log)\n",
    "qqqLogPriceEG2018 = np.log(eg_basket_data2018['qqqclose'].values)\n",
    "\n",
    "syntheticAssetLogPriceJoh2018 = joh_basket_data2018[['hasclose', 'ttwoclose', 'sbuxclose', \n",
    "                               'idxxclose', 'ctasclose', 'alxnclose']].apply(np.log)\n",
    "qqqLogPriceJoh2018 = np.log(joh_basket_data2018['qqqclose'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_eg2018 = fn.multivariateKalmanFilter(syntheticAssetLogPriceEG2018, qqqLogPriceEG2018)\n",
    "state_means_eg2018, state_covs_eg2018 = kf_eg2018.filter(qqqLogPriceEG2018)\n",
    "basket_size_eg2018 = len(syntheticAssetLogPriceEG2018.columns)\n",
    "slopes_eg2018 = state_means_eg2018[:, np.arange(0, basket_size_eg2018, 1)]\n",
    "#intercept2018 = state_means2018[:, basket_size2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntheticAssetEstimateEG2018 = [np.dot(slopes_eg2018[i], syntheticAssetLogPriceEG2018.values[i].T)\n",
    "                              for i in range(len(slopes_eg2018))]\n",
    "spread_ts_eg2018 = qqqLogPriceEG2018- syntheticAssetEstimateEG2018\n",
    "eg_basket_data2018.reset_index(inplace=True)\n",
    "eg_basket_data2018 = eg_basket_data2018.rename(columns={'index': 'datetime'})\n",
    "eg_basket_data2018['logspread'] = spread_ts_eg2018\n",
    "eg_basket_data2018['spread'] = np.exp(spread_ts_eg2018)\n",
    "\n",
    "eg_backtest_data2018 = eg_basket_data2018[['datetime', 'qqqclose', 'hasclose', 'aaplclose', 'ttwoclose', 'sbuxclose', \n",
    "                      'ctasclose', 'alxnclose', 'algnclose', 'payxclose', 'spread']]\n",
    "diff_thresh_eg = fn.calculateDiffThresh(eg_backtest_data2018, q=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff_thresh_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_Joh2018 = fn.multivariateKalmanFilter(syntheticAssetLogPriceJoh2018, qqqLogPriceJoh2018)\n",
    "state_means_joh2018, state_covs_joh2018 = kf_Joh2018.filter(qqqLogPriceJoh2018)\n",
    "basket_size_joh2018 = len(syntheticAssetLogPriceJoh2018.columns)\n",
    "slopes_joh2018 = state_means_joh2018[:, np.arange(0, basket_size_joh2018, 1)]\n",
    "#intercept = state_means[:, basket_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntheticAssetEstimateJoh2018 = [np.dot(slopes_joh2018[i], syntheticAssetLogPriceJoh2018.values[i].T)\n",
    "                              for i in range(len(slopes_joh2018))]\n",
    "spread_ts_joh2018 = qqqLogPriceJoh2018- syntheticAssetEstimateJoh2018\n",
    "joh_basket_data2018.reset_index(inplace=True)\n",
    "joh_basket_data2018 = joh_basket_data2018.rename(columns={'index': 'datetime'})\n",
    "joh_basket_data2018['logspread'] = spread_ts_joh2018\n",
    "joh_basket_data2018['spread'] = np.exp(spread_ts_joh2018)\n",
    "\n",
    "joh_backtest_data2018 = joh_basket_data2018[['datetime', 'qqqclose', 'hasclose','ttwoclose', 'sbuxclose', \n",
    "                      'ctasclose', 'alxnclose', 'spread']]\n",
    "diff_thresh_joh = fn.calculateDiffThresh(joh_backtest_data2018, q=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff_thresh_joh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest and Out-of-Sample Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_data = pd.read_csv(\"../data/eg_basket_data.csv\")\n",
    "joh_data = pd.read_csv(\"../data/joh_basket_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_backtest_data = eg_data[['datetime', 'qqqclose', 'hasclose', 'aaplclose', 'ttwoclose', 'sbuxclose', \n",
    "                      'ctasclose', 'alxnclose', 'algnclose', 'payxclose', 'spread']]\n",
    "eg_backtest_data = fn.createBands(eg_backtest_data, params_eg[0], params_eg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "plt.plot(eg_backtest_data['spread'].iloc[-450:])\n",
    "plt.plot(eg_backtest_data['upperband'].iloc[-450:], color='g')\n",
    "plt.plot(eg_backtest_data['ema'].iloc[-450:], color='y')\n",
    "plt.plot(eg_backtest_data['lowerband'].iloc[-450:], color='r')\n",
    "plt.title(\"Engle-Granger Basket Spread and Dynamic Thresholds (Out-of-Sample)\")\n",
    "plt.ylabel(\"Spread ($)\")\n",
    "plt.xlabel(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joh_backtest_data = joh_data[['datetime', 'qqqclose', 'hasclose', 'ttwoclose', 'sbuxclose', \n",
    "                               'idxxclose', 'ctasclose', 'alxnclose', 'spread']]\n",
    "joh_backtest_data = fn.createBands(joh_backtest_data, params_joh[0], params_joh[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "plt.plot(joh_backtest_data['spread'].iloc[-450:])\n",
    "plt.plot(joh_backtest_data['upperband'].iloc[-450:], color='g')\n",
    "plt.plot(joh_backtest_data['ema'].iloc[-450:], color='y')\n",
    "plt.plot(joh_backtest_data['lowerband'].iloc[-450:], color='r')\n",
    "plt.title(\"Johansen Basket Spread and Dynamic Thresholds (Out-of-Sample)\")\n",
    "plt.ylabel(\"Spread ($)\")\n",
    "plt.xlabel(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Signals and Positions\n",
    "Positions are generated based on the thresholds determined in the in-sample period.  When the spread is below our lower threshold, a long signal is generated and we enter a long spread position in the subsequent minute.  Symmetrically, when the spread is above our upper threshold, a short signal is generated and we enter a short spread position in the subsequent minute.  When the spread reverts back to the mean from our in-sample period, we close our positions.\n",
    "\n",
    "For our optimal positions, we aim to forecast the mean reversion by not only conditioning that the spread is above/below the upper/lower threshold, but also conditioning that the percentage difference in spread magnitude is in the bottom 20% of our in-sample period's percentage difference in spread from minute to minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_final_data = fn.createPositions(eg_backtest_data.copy()) # no overnight positions, all positions exited by EOD\n",
    "eg_final_data_opt = fn.createOptimalPositions(eg_backtest_data.copy(), threshold=diff_thresh_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joh_final_data = fn.createPositions(joh_backtest_data.copy()) # no overnight positions, all positions exited by EOD\n",
    "joh_final_data_opt = fn.createOptimalPositions(joh_backtest_data.copy(), threshold=diff_thresh_joh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade Log\n",
    "The trade log is generated to compile all the individual trades executed in our backtest and some information about them.  This includes the start and end time, the holding period, what position was taken (long or short), position size and value, as well as profit and return information.  The information in this dataset can be used to analyze the strategy and the properties of the trades executed by the strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engle-Granger Basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_eg = eg_data[['hasSlope', 'aaplSlope', 'ttwoSlope', 'sbuxSlope', 'ctasSlope', 'alxnSlope', 'algnSlope', 'payxSlopes']]\n",
    "prices_eg = eg_final_data[['hasclose', 'aaplclose', 'ttwoclose', 'sbuxclose', \n",
    "                       'ctasclose', 'alxnclose', 'algnclose', 'payxclose']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tradeLog_eg, minuteDf_eg = fn.constructTradeLog(eg_final_data['datetime'].values, eg_final_data['position'].values,\n",
    "                               eg_final_data['qqqclose'].values, prices_eg, \n",
    "                               slopes_eg.values.round(3), stoploss = None,\n",
    "                               lot_size = 1000)\n",
    "tradeLog_eg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeLog_eg_opt, minuteDf_eg_opt = fn.constructTradeLog(eg_final_data_opt['datetime'].values, \n",
    "                                                        eg_final_data_opt['position'].values,\n",
    "                                                        eg_final_data_opt['qqqclose'].values, prices_eg, \n",
    "                                                        slopes_eg.values.round(3), stoploss = None,\n",
    "                                                        lot_size = 1000)\n",
    "tradeLog_eg_opt.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "returns_df_eg = minuteDf_eg[['datetime']]\n",
    "returns_df_eg['cumulative_returns'] = np.cumprod(1 + minuteDf_eg['returns'])\n",
    "returns_df_eg['cumulative_returns_opt'] = np.cumprod(1 + minuteDf_eg_opt['returns'])\n",
    "returns_df_eg = returns_df_eg.set_index('datetime')\n",
    "returns_df_eg.plot(figsize=[15, 7], title='Engle-Granger Basket Strategy Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_eg = fn.calculateDailyReturns(minuteDf_eg[['returns', 'datetime']])\n",
    "daily_eg_opt = fn.calculateDailyReturns(minuteDf_eg_opt[['returns', 'datetime']])\n",
    "sharpe_eg = fn.calculateAnnualizedSharpeRatio(daily_eg)\n",
    "sharpe_eg_opt = fn.calculateAnnualizedSharpeRatio(daily_eg_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Engle-Granger Basket Backtest Results\")\n",
    "print(\"Returns: \", (returns_df_eg['cumulative_returns'].iloc[-1] - 1) * 100, '%')\n",
    "print(\"Returns (Optimized): \", (returns_df_eg['cumulative_returns_opt'].iloc[-1] - 1) * 100, '%')\n",
    "print(\"Sharpe: \", sharpe_eg)\n",
    "print(\"Sharpe (Optimized)\", sharpe_eg_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Johansen Basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_joh = joh_data[['hasSlope', 'ttwoSlope', 'sbuxSlope', 'idxxSlope', 'ctasSlope', 'alxnSlope']]\n",
    "prices_joh = joh_final_data[['hasclose', 'ttwoclose', 'sbuxclose', 'idxxclose', 'ctasclose', 'alxnclose']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tradeLog_joh, minuteDf_joh = fn.constructTradeLog(joh_final_data['datetime'].values, joh_final_data['position'].values,\n",
    "                               joh_final_data['qqqclose'].values, prices_joh, \n",
    "                               slopes_joh.values.round(3), stoploss = None,\n",
    "                               lot_size = 1000)\n",
    "tradeLog_joh.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeLog_joh_opt, minuteDf_joh_opt = fn.constructTradeLog(joh_final_data_opt['datetime'].values, \n",
    "                                                          joh_final_data_opt['position'].values,\n",
    "                                                          joh_final_data_opt['qqqclose'].values, prices_joh, \n",
    "                                                        slopes_joh.values.round(3), stoploss = None,\n",
    "                                                        lot_size = 1000)\n",
    "tradeLog_joh_opt.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "returns_df_joh = minuteDf_joh[['datetime']]\n",
    "returns_df_joh['cumulative_returns'] = np.cumprod(1 + minuteDf_joh['returns'])\n",
    "returns_df_joh['cumulative_returns_opt'] = np.cumprod(1 + minuteDf_joh_opt['returns'])\n",
    "returns_df_joh = returns_df_joh.set_index('datetime')\n",
    "returns_df_joh.plot(figsize=[15, 7], title='Johansen Basket Strategy Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_joh = fn.calculateDailyReturns(minuteDf_joh[['returns', 'datetime']])\n",
    "daily_joh_opt = fn.calculateDailyReturns(minuteDf_joh_opt[['returns', 'datetime']])\n",
    "sharpe_joh = fn.calculateAnnualizedSharpeRatio(daily_joh)\n",
    "sharpe_joh_opt = fn.calculateAnnualizedSharpeRatio(daily_joh_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Johansen Basket Backtest Results\")\n",
    "print(\"Returns: \", (returns_df_joh['cumulative_returns'].iloc[-1] - 1) * 100, '%')\n",
    "print(\"Returns (Optimized): \", (returns_df_joh['cumulative_returns_opt'].iloc[-1] - 1) * 100, '%')\n",
    "print(\"Sharpe: \", sharpe_joh)\n",
    "print(\"Sharpe (Optimized)\", sharpe_joh_opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
